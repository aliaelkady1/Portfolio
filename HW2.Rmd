---
output:
  html_document: default
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Peer Grader Guidance
Please review the student expectations for peer review grading and peer review comments. Overall, we ask that you score with accuracy. When grading your peers, you will not only learn how to improve your future homework submissions but you will also gain deeper understanding of the concepts in the assignments. When assigning scores, consider the responses to the questions given your understanding of the problem and using the solutions as a guide. Moreover, please give partial credit for a concerted effort, but also be thorough. **Add comments to your review, particularly when deducting points, to explain why the student missed the points.** Ensure your comments are specific to questions and the student responses in the assignment.


# Background

The provided dataset is a subset of the public data from the 2022 EPA Automotive Trends Report. It will be used to study the effects of various vehicle characteristics on CO2 emissions.

## Data Description

The dataset consists of a dataframe with 2060 observations with the following 7 variables:

1. Model.Year: year the vehicle model was produced (quantitative)
2. Type: vehicle type (qualitative)
3. MPG: miles per gallon of fuel (quantitative)
4. Weight: vehicle weight in lbs (quantitative)
5. Horsepower: vehicle horsepower in HP (quantitative)
6. Acceleration: acceleration time (from 0 to 60 mph) in seconds (quantitative)
7. CO2: carbon dioxide emissions in g/mi (response variable)


## Instructions on reading the data

To read the data in `R`, save the file in your working directory (make sure you have changed the directory if different from the R working directory) and read the data using the `R` function `read.csv()`
```{r}
# reading the dataset
data <- read.csv("vehicle_CO2_emis.csv")
head(data,3)
```


# Question 1: Exploratory Data Analysis [15 points]

a. **3 pts** Compute the correlation coefficient for each quantitative predicting variable (Model.Year, MPG, Weight, Horsepower, Acceleration) against the response (CO2). Describe the strength and direction of the top 3 predicting variables that have the strongest linear relationships with the response.

```{r}
cor(data[,-2],data[,7])
```

**Q1a ANSWER:** 
The top three variables with the strongest relationship with the response variable are: MPG, weight, and model year. 
MPG has the strongest (negative) relationship with the response variables with a correlation coefficient of -0.96. This can be interpreted as the cars that have lower miles per gallon of fuel tend to have the highest CO2 emissions. This observations is consistent across the data given the strong relationship.    
Weight comes in next with a moderate positive correlation coefficient of 0.52. This can mean that, generally, as the car has a higher weight, it tends to have a higher CO2 emission value.    
Model year comes third with a moderate negative correlation coefficient of -0.48. This can meant that, generally, latest car models tend to have lower CO2 emission values. 

b. **3 pts** Create a boxplot of the qualitative predicting variable (Type) versus the response (CO2). Explain the relationship between the two variables.
```{r}
boxplot(CO2~Type,xlab="Type",ylab="CO2 Emission",data=data)

```

**Q1b ANSWER:** 
There are several things we can comment on from this boxplot:
1. The median score for Sedan type cars is lower than the other types, which indicates that Sedans tend to have lower CO2 emission values. This is also supported by it having the smallest (shortest) box, meanining that this observation is quite consistent.
2. SUV cars have the most variability in their CO2 emission values evident by it having the longest box.



c. **6 pts** Create scatterplots of the response (CO2) against each quantitative predicting variable (Model.Year, MPG, Weight, Horsepower, Acceleration). Describe the general trend of each plot.
```{r}
plot(data$Model.Year, data$CO2)
plot(data$Weight, data$CO2)
plot(data$Horsepower, data$CO2)
plot(data$Acceleration, data$CO2)
plot(data$MPG, data$CO2)
```

**Q1c ANSWER:** 
Model year x CO2: most of the latest car models tend to have lower CO2 emission values than earlier models. There is a general negative relationship.
Weight x CO2: there is a positive correlation between the weight of the car and its CO2 emission. As the weight increases, the CO2 emission increases, however, the slope is not that steep.
Horsepower x CO2: there is almost no relationship between horsepower and CO2. One might observe a very slight positive relationship, however it is not conclusive.
Acceleration x CO2:
MPG x CO2: there is a strong negative relationship, the lower the MPG, the higher the CO2 emission.

d. **3 pts** Based on this exploratory analysis, is it reasonable to fit a multiple linear regression model for the relationship between CO2 and the predicting variables? Explain how you determined the answer.


**Q1d ANSWER:** 
I believe it is reasonable to fit a multiple linear regression as the combination of these variables might help us explain the variability in CO2 emissions. The model might not be very helpful for prediction, but it can be helpful for modeling; explaining the variability.

# Question 2: Model Fitting and Interpretation [26 points]

a. **3 pts** Fit a multiple linear regression model called model1 using CO2 as the response and the top 3 predicting variables with the strongest relationship with CO2, from Question 1a.
```{r}
predictors = as.data.frame(cbind(data$Model.Year,data$Weight,data$MPG,data$CO2))
colnames(predictors) = c('Model.Year','Weight','MPG','CO2')
model1 = lm(CO2~., data=predictors)
summary(model1)

```


b. **4 pts** What is the estimated coefficient for the intercept? Interpret this coefficient in the context of the dataset.

**Q2b ANSWER:** 
The estimated coefficient for the intercept is 3.764e+03. This means that when all the predictors are equal to 0, the estimated change in the response variable (CO2 emission) will be 3.764e+03.

c. **4 pts** Assuming a marginal relationship between Type and CO2, perform an ANOVA F-test on the mean CO2 emission among the different vehicle types. Using an $\alpha$-level of 0.05, is Type useful in predicting CO2? Explain how you determined the answer.
```{r}
aovModel = aov(CO2 ~ Type, data = data)
summary(aovModel)
```

**Q2c ANSWER:** 
Given that the p-value (<2e-16) is way smaller than 0.05, this suggests that the differences in the mean CO2 emission among the different vehicle types is significantly different, therefore, 'Type' can be useful in predicting CO2.   

d. **3 pts** Fit a multiple linear regression model called model2 using CO2 as the response and all predicting variables. Using $\alpha = 0.05$, which of the estimated coefficients that were statistically significant in model1 are also statistically significant in model2?
```{r}
data$Type <- factor(data$Type) #ensuring that Type is categorical(factor)
data$Type <- relevel(data$Type, ref="Sedan") #ensuring that Sedan is the baseline.
model2 = lm(CO2~. , data = data)
summary(model2)
```

**Q2d ANSWER:** 
All three (year, weight, MPG) variables that were statistically significant in model 1 are also statistically significant in model 2. 

e. **4 pts** Interpret the estimated coefficient for TypeVan in the context of the dataset. Make sure TypeSedan is the baseline level for Type. Mention any assumptions you make about other predictors clearly when stating the interpretation.

**Q2e ANSWER:** 
The estimated coefficient for TypeVan is -2.440e+01, which means that, on average, the CO2 emissions for vans is -2.440e+01 units lower than that of sedans assuming all other predictors are held constant. Other assumptions we did that allow this interpretation to be valid is constant variance and normality of errors.

f. **4 pts** How does your interpretation of TypeVan above compare to the relationship between CO2 vs Type analyzed using the boxplot in Q1? Explain the reason for the similarities/differences.

**Q2f ANSWER:** 
It is very much different. My interpretation in Q2e is against what is shown in the boxplot. In the boxplot it suggests that vans, on average, tend to have a higher CO2 emission that sedans, but as we saw in Q2e, vans has a negative coefficient compared to the baseline. This can be justified because the boxplot was an example of visualizing a marginal model, which is one that captures the association of one predicting variable to the response without consideration of other factors. My answer for Q2e is based on a conditional model, which is one that captures the association of a predicting variable to the response, taking into consideration other predicting variables in the model.

g. **4 pts** Is the overall regression (model2) significant at an $\alpha$-level of 0.05? Explain how you determined the answer.

**Q2g ANSWER:** 
The obtained p-value for model2 is < 2.2e-16, which is statistically significant since it is way smaller than 0.05. This means that we reject the null hypothesis meaning that at least one of the predictive variables has predictive power.

# Question 3: Model Comparison, Outliers, and Multicollinearity [16 points]
a. **4 pts** Conduct a partial $F$-test comparing model1 and model2. What can you conclude from the results using an $\alpha$-level of 0.05?
```{r}
anova(model1,model2)
```

**Q3a ANSWER:** 
Given that the p-value is almost 0 (< 2.2e-16), we reject the null hypothesis that the coefficients of the added predictors are all zero.

b. **4 pts** Using $R^2$ and adjusted $R^2$, compare model1 and model2.
```{r}
summary(model1)
summary(model2)
```

**Q3b ANSWER:** 
The R^2 and adjusted R^2 for model1 are: 0.9322 and 0.9321
The R^2 and adjusted R^2 for model2 are: 0.9417 and 0.9414
Model 1 explains 93% of the variability in the response variable, while model 2 explains 94%.
Given that both models are of different size, so to compare directly between them we need to use the adjusted R^2 value, as it penalizes for the addition of  predictors because R^2 naturally increases with the addition of more predictors.
Model2 has a higher adjusted R^squared.

c. **4 pts** Create a plot for the Cook's Distances (use model2). Using a threshold of 1, are there any outliers? If yes, which data points?
```{r}
cook = cooks.distance(model2)
plot(cook, type="h",lwd=3,col="red",ylab="Cook's Distance")
```

**Q3c ANSWER:** 
While there are 2 peaks that seem very different from the rest, using a threshold of 1 shows no outliers.

d. **4 pts** Calculate the VIF of each predictor (use model2). Using a threshold of max(10, 1/(1-$R^2$)) what conclusions can you make regarding multicollinearity?
```{r}
library(car)
vif(model2)
```

**Q3d ANSWER:** 
Given our threshold of max(10, 1/(1-$R^2$)), 1/(1-0.94) evaluates to approx 16.67. Therefore, given the above VIF values, there seems to be no multicollinearity. 

# Question 4: Prediction [3 points]

**3 pts** Using model1 and model2, predict the CO2 emissions for a vehicle with the following characteristics:
Model.Year=2020,
Type="Sedan",
MPG=32,
Weight=3400,
Horsepower=203,
Acceleration=8
```{r}
point = data.frame(Model.Year=2020, Type="Sedan", MPG=32, Weight=3400, Horsepower=203,Acceleration=8)
predicted_CO2_model1 = predict(model1, newdata=point)
predicted_CO2_model2 = predict(model2, newdata=point)
```

**Q4 ANSWER:**
The predicted CO2 is 224 using model1 (3 predictors)
The predicted CO2 is 227 using model2 (all predictors)
